import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
import warnings
import os
from pathlib import Path
from sklearn.metrics import mean_squared_error

from basemodel import *

warnings.filterwarnings('ignore')

def finetune_model(base_model_path, new_data_path, output_path, features_list):
    """
    HÃ m Fine-tune: Cáº­p nháº­t mÃ´ hÃ¬nh cÅ© vá»›i dá»¯ liá»‡u má»›i.
    """
    base_model_path = str(base_model_path)
    output_path = str(output_path)
    
    print(f"\nğŸ”§ Báº®T Äáº¦U FINE-TUNE MÃ” HÃŒNH Tá»ª: {base_model_path}")
    
    # 1. LOAD MÃ” HÃŒNH Gá»C (BASE MODEL)
    if not os.path.exists(base_model_path):
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file model gá»‘c táº¡i {base_model_path}")
        return

    model = joblib.load(base_model_path)
    print("âœ… ÄÃ£ load xong model gá»‘c.")

    # 2. LOAD METADATA (Äá»ƒ biáº¿t ngÃ y xÆ°a train dÃ¹ng cá»™t nÃ o)
    meta_path = base_model_path.replace('.pkl', '_features.pkl')
    try:
        input_cols_old, features_old = joblib.load(meta_path)
        print("âœ… ÄÃ£ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c cáº¥u trÃºc input/output cÅ©.")
    except:
        print("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file metadata (_features.pkl). KhÃ´ng thá»ƒ fine-tune chuáº©n.")
        return

    # 3. CHUáº¨N Bá»Š Dá»® LIá»†U Má»šI (FINE-TUNE DATA)
    # LÆ°u Ã½: Pháº£i dÃ¹ng logic y há»‡t nhÆ° lÃºc train base model
    print(f"ğŸ”„ Äang xá»­ lÃ½ dá»¯ liá»‡u má»›i tá»«: {new_data_path}")
    df_ft, _ = prepare_time_series_data(new_data_path, features_list, lags=[1, 4])
    
    if df_ft is None or len(df_ft) == 0:
        print("âš ï¸ Dá»¯ liá»‡u fine-tune trá»‘ng hoáº·c khÃ´ng Ä‘á»§ Ä‘á»ƒ táº¡o lag. Há»§y bá».")
        return

    # Äáº£m báº£o dá»¯ liá»‡u má»›i cÃ³ Ä‘á»§ cÃ¡c cá»™t nhÆ° dá»¯ liá»‡u cÅ©
    # (Náº¿u thiáº¿u cá»™t nÃ o thÃ¬ Ä‘iá»n 0 hoáº·c bÃ¡o lá»—i, á»Ÿ Ä‘Ã¢y ta giáº£ Ä‘á»‹nh dá»¯ liá»‡u chuáº©n)
    X_new = df_ft[input_cols_old]
    y_new = df_ft[features_list]

    print(f"ğŸ“Š KÃ­ch thÆ°á»›c dá»¯ liá»‡u Fine-tune: {len(X_new)} máº«u")

    # 4. THá»°C HIá»†N FINE-TUNE (Cáº¬P NHáº¬T TRá»ŒNG Sá»)
    # VÃ¬ model lÃ  MultiOutputRegressor (chá»©a nhiá»u model con), ta pháº£i update tá»«ng cÃ¡i
    
    print("â³ Äang cáº­p nháº­t kiáº¿n thá»©c má»›i cho mÃ´ hÃ¬nh...")
    
    # Duyá»‡t qua tá»«ng model con (tÆ°Æ¡ng á»©ng tá»«ng cá»™t output: DO, pH, Temp...)
    for i, estimator in enumerate(model.estimators_):
        target_name = features_list[i]
        
        # A. Láº¥y "bá»™ nÃ£o" (booster) cá»§a model cÅ© ra
        old_booster = estimator.get_booster()
        
        # B. Giáº£m tá»‘c Ä‘á»™ há»c (Learning Rate)
        # Khi fine-tune, ta nÃªn há»c cháº­m láº¡i Ä‘á»ƒ khÃ´ng "quÃªn" kiáº¿n thá»©c cÅ© quÃ¡ nhanh
        estimator.set_params(learning_rate=0.005) 
        
        # C. Train tiáº¿p (Incremental Learning)
        # Tham sá»‘ quan trá»ng nháº¥t: xgb_model=old_booster
        # NghÄ©a lÃ : "Äá»«ng há»c tá»« Ä‘áº§u, hÃ£y há»c tiáº¿p tá»« cÃ¡i cÅ©"
        estimator.fit(X_new, y_new.iloc[:, i], xgb_model=old_booster)
        
    # 5. ÄÃNH GIÃ Láº I TRÃŠN Dá»® LIá»†U Má»šI
    print("\nğŸ“Š Káº¾T QUáº¢ SAU KHI FINE-TUNE (TRÃŠN Táº¬P Dá»® LIá»†U Má»šI):")
    print("-" * 50)
    y_pred = model.predict(X_new)
    rmse = np.sqrt(mean_squared_error(y_new, y_pred, multioutput='raw_values'))
    
    for i, col_name in enumerate(features_list):
        print(f"   ğŸ”¹ {col_name:<15} RMSE: {rmse[i]:.4f}")
    
    print("-" * 50)
    print(f"ğŸ‘‰ RMSE trung bÃ¬nh: {np.mean(rmse):.4f}")

    # 6. LÆ¯U MÃ” HÃŒNH Má»šI (FINETUNED MODEL)
    joblib.dump(model, output_path)
    # LÆ°u luÃ´n metadata cho model má»›i (thá»±c ra váº«n y há»‡t cÃ¡i cÅ©)
    joblib.dump((input_cols_old, features_list), output_path.replace('.pkl', '_features.pkl'))
    
    print(f"\nğŸ‰ ÄÃ£ lÆ°u model Fine-tune táº¡i: {output_path}")


if __name__ == "__main__":
    # --- Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ---
    BASE_DIR = Path(__file__).resolve().parent
    PROJECT_DIR = BASE_DIR.parent
    
    # ÄÆ°á»ng dáº«n model gá»‘c (Base Model)
    MODEL_DIR = PROJECT_DIR / "model" / "output"
    BASE_COBIA_MODEL = MODEL_DIR / "hk_cobia_forecast_model.pkl"
    
    # ÄÆ°á»ng dáº«n dá»¯ liá»‡u má»›i Ä‘á»ƒ Fine-tune (VÃ­ dá»¥: Dá»¯ liá»‡u nÄƒm 2024 má»›i vá», hoáº·c dá»¯ liá»‡u riÃªng cá»§a 1 vÃ¹ng)
    # á» Ä‘Ã¢y tÃ´i dÃ¹ng láº¡i file csv cÅ© lÃ m vÃ­ dá»¥, thá»±c táº¿ báº¡n thay báº±ng file má»›i
    NEW_DATA_PATH = PROJECT_DIR / "data" / "data_quang_ninh" / "qn_env_clean_ready.csv"
    
    # ÄÆ°á»ng dáº«n lÆ°u model má»›i
    OUTPUT_FINETUNE = MODEL_DIR / "hk_cobia_finetuned.pkl"

    print(f"ğŸ“‚ Base Model: {BASE_COBIA_MODEL}")

    # Cháº¡y Fine-tune cho CÃ GIÃ’ (VÃ­ dá»¥)
    finetune_model(
        base_model_path = BASE_COBIA_MODEL,
        new_data_path = NEW_DATA_PATH,
        output_path = OUTPUT_FINETUNE,
        features_list = COBIA_FEATURES
    )